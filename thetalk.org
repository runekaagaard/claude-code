* [CLAUDE: Title type slide]
Claude Code in Practice
Making It Work on Large Projects

* From Scissors to Shipping Code
- 1920 Physical cut-up method with scissors
- 1995 Verbasizer 2.0 digital randomization
- 2019 AI Dungeon interactive text generation
- 2022 ChatGPT browser-based prompting
- 2024 Tools/MCP servers provide filesystem access
- 2025 Agentic coding assistants with full workflow automation

* About 
** Rune Kaagaard
- CTO Prescriba
- Psychological/Psychiatric services
- 50.000 Clients/year
- Composer & Pianist
- Dragør

** runekaagaard@github
- https://github.com/runekaagaard
- https://github.com/runekaagaard/mcp-alchemy - Relational Databases 
- https://github.com/runekaagaard/mcp-redmine) - Redmine Project Management
- https://github.com/runekaagaard/mcp-notmuch-sendmail - Send/Receive Email
- hypergen.it - Django Liveview

** This Talk
- Building features fast without losing control
- MCP servers: Your tools become Claude's tools
- Worktrees and workflows for parallel development
- Root to leaves: Foundation first, details last

* [CLAUDE: Title type slide]
npm install -g @anthropic-ai/claude-code
claude

* Claude Code
- Agentic Code Editor
- Command Line
- Multimodal
- Batteries included
- Fuzzy & Random
- Hooks, Commands, Skills, Plugins

** Batteries
[CLAUDE: make 4x4 cards of these]
- Task: Launch specialized sub-agents for complex, multi-step autonomous work
- Bash: Execute shell commands in persistent sessions for builds, tests, automation
- Glob: Fast file pattern matching (e.g., **/*.js, src/**/*.ts)
- Grep: Powerful content search using ripgrep with regex support
- Read: Read text files, images, PDFs, and Jupyter notebooks
- Edit: Exact string replacements in files
- Write: Write or overwrite files with new content
- NotebookEdit: Edit Jupyter notebook cells (replace, insert, delete)
- WebFetch: Fetch and process web content with AI analysis
- WebSearch: Search the web for current information (US only)
- TodoWrite: Create and manage structured task lists for progress tracking
- ExitPlanMode: Exit plan mode after presenting implementation plan
- BashOutput: Retrieve output from running background bash shells
- KillShell: Terminate running background bash shell processes
- SlashCommand: Execute custom slash commands
- gh: Command line Github integration

* MCP Servers
- Give Claude code access to all your stuff
- Database, Browser Automation, Design tools, Messaging
- Write your own!
- Keep it small

** Value proposition
#+begin_src bash
$ pip install mcp[cli]
#+end_src

#+begin_src python
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("Multiply Server")

@mcp.tool(structured_output=False)
def multiply(a: float, b: float) -> str:
    """
    Multiply two numbers together.
    
    Args:
        a: First number
        b: Second number
    
    return str(a * b)

if __name__ == "__main__":
    mcp.run()
#+end_src

** mcp_config.json
#+begin_src json
{
  "mcpServers": {
    "multiply": {
      "command": "python",
      "args": ["/path/to/mcp-multiply/server.py"]
    },
    "database": {
      "command": "uvx",
      "args": ["--from", "mcp-alchemy==2025.8.15.91819",
               "--refresh-package", "mcp-alchemy", "mcp-alchemy"],
      "env": {
        "DB_URL": "sqlite:///path/to/database.db"
      }
    },
    "email": {
      "command": "uvx",
      "args": ["--from", "mcp-notmuch-sendmail==2025.04.09.174710",
               "--refresh-package", "mcp-notmuch-sendmail", "mcp-notmuch-sendmail"],
      "env": {
        "NOTMUCH_DATABASE_PATH": "/path/to/notmuch/db",
        "SENDMAIL_FROM_EMAIL": "you@example.com"
      }
    },
    "redmine": {
      "command": "uvx",
      "args": ["--from", "mcp-redmine==2025.09.03.141435",
               "--refresh-package", "mcp-redmine", "mcp-redmine"],
      "env": {
        "REDMINE_URL": "https://redmine.example.com",
        "REDMINE_API_KEY": "your-api-key"
      }
    }
  }
}
#+end_src

** What's a good MCP server?
- As few tools as possible
- Add discoverability to existing programs
- Don't change the documentation, just change the tool
- Change interface to something the model likes
- OpenAPI's are great

** MCP Server API examples
| Operation  | MCP Alchemy        | Notmuch Sendmail      | Redmine        |
|------------+--------------------+-----------------------+----------------|
| Discovery  | all_table_names    | find_email_thread     | paths_list     |
|            | filter_table_names |                       | request        |
|            | schema_definitions |                       |                |
|------------+--------------------+-----------------------+----------------|
| Retrieval  | execute_query      | view_email_thread     | paths_info     |
|            |                    | read_email_attachment | request        |
|------------+--------------------+-----------------------+----------------|
| Mutation   | execute_query      | compose_new_email     | request        |
|            |                    | compose_email_reply   |                |
|            |                    | send_email            |                |
|------------+--------------------+-----------------------+----------------|
| Utility    |                    | sync_emails           | upload         |
|            |                    |                       | download       |

* Documentation
** CLAUDE.md
- Project instructions that persists across sessions
- Tech stack, modules, conventions, where to find things
- Don't use directory CLAUDE.md's

** llm/[app1.md,app2.md,...]
- Full source too big for context
- Document each app separately, then add cross cutting concerns
- Module-specific documentation
- Cross-cutting concerns
- "Be sure to read relevant llm files in the @llm folder"

** Repomix
#+begin_src bash
# Generate with repomix
for app in src/apps/*; do
  appname=$(basename $app)
  repomix --include "$app/**" --style markdown \
    --output "repomix-$appname.md"
  claude -p -c "Read @repomix-$appname.md then follow \
    instructions in @llm/how_to_document_an_app.md and \
    generate llm/$appname.md"
done
#+end_src

** Cross cutting concerns
#+begin_src markdown
Dear Claude:

- please read all the app documentation files in @llm/ and research cross-cutting concerns
- update each llm/[app].md file with these details
#+end_src

* Development Setup
- What makes developers happy makes Claude effective
- Fast dev environment creation
- Local databases with real data
- Tests for AI feedback loop
- Auto port discovery across workspaces
- Branch name visible in UI

** Worktrees
- Claude Code conversations are directory specific
- Worktrees over branch switching
- Each task gets isolated directory
- Work on multiple features simultaneously

** Create worktree
#+begin_src bash
git worktree add -b mybranch ~/worktrees/mybranch origin/main
cd ~/worktrees/mybranch
git commit --allow-empty -m "Initial commit"
git push -u origin mybranch
#+end_src

#+begin_src bash
# Makefile
worktree-setup-symlink:
    ln -sf ~/main/node_modules .
    ...
#+end_src

#+begin_src bash
claude-terminator-workspace ~/worktrees/1234_mybranch/
#+end_src

** Multiple Claude Code's
- Tmux
- Scripted terminal
- Web UI
- Terminal wrappers


* Lets start building stuff
#+begin_src bash
# New claude session
cl() {
   unset ANTHROPIC_API_KEY
   claude --mcp-config ~/claude_code_config.json "$@"
}

# Continue claude session
clc() {
   unset ANTHROPIC_API_KEY
   claude --continue --mcp-config ~/claude_code_config.json "$@"
}

# Project manager
clp() {
   unset ANTHROPIC_API_KEY
   claude --continue --add-dir ~/worktrees --mcp-config ~/claude_code_config.json "$@"
}
#+end_src

#+begin_src markdown
/issue Please create a new issue for: My Awesome New Feature
#+end_src

** /issue command
#+begin_src markdown
---
description: Manage issues, branches, PR's, worktrees and workspaces
---

Please process these instructions: $ARGUMENTS

# Issues

- Use the redmine tools
- The issue id is in the branch name

# Branches
...

## Output

✅ Created:
- Issue #[NUM]: [TITLE]
  [ISSUE_URL]
- Branch: [BRANCH_NAME]
- PR: [PR_URL]
- Worktree: ~/worktrees/[BRANCH_NAME]

* Exploration and Research
- Make Claude use a lot of tokens
- Great way to refresh your own understanding
- Follow up for additional details
- Stepwise approach makes good todo items

** Prompt
#+begin_src markdown
Hi Claude, let's start by researching how rate limiting works in the system.

First read:
- The current issue in Redmine
- Any referenced emails
- Relevant documentation in the @llm folder

Then read these core files in full:
- @src/middleware/ratelimit.py
- @src/models/api_key.py

After that, reference relevant functions in src/cache/redis_client.py and do additional research as needed.

Finally, summarize your findings.
#+end_src

** Realpath
#+begin_src bash
# Get absolute paths for files
$ realpath [file1] [file2]
#+end_src

#+begin_src elisp
(defun rk-realpath ()
  "Copy the full path of current buffer to kill ring"
  (interactive)
  (kill-new (buffer-file-name))
  (message "Copied: %s" (buffer-file-name)))

(defun rk-realpath-visible-buffers ()
  "Copy a newline separated list of full paths of visible buffers to kill ring."
  (interactive)
  (let ((paths '()))
    ;; Collect paths from all visible buffers
    (dolist (frame (frame-list))
      (dolist (window (window-list frame))
        (let* ((buffer (window-buffer window))
               (path (buffer-file-name buffer)))
          (when path
            (push path paths)))))

    ;; Create newline separated string and kill it
    (let ((paths-str (mapconcat #'identity (delete-dups (nreverse paths)) "\n")))
      (kill-new paths-str)
      (message "Copied %d visible buffer paths" (length (split-string paths-str "\n" t))))))
#+end_src

* Planning
- What are we building?
- How will we build it?
- Ask for questions and answer them
- Don't use plan mode
- "Don't code"
- "Lets imagine something bad happens to us if we don't get this right"

** Prompt
#+begin_src markdown
Today we are replacing the old rate limiter with Redis HyperLogLog counting. I'm thinking we use this overall approach:

- Use PFCOUNT for approximate unique IP counting per window
- Store window metadata in Django models
- Celery task to persist stats every hour

Any questions? Feel free to do additional research before we start coding.
#+end_src

#+begin_src markdown
Great questions, I'm thinking the following:

1. Yes, 1% error rate on HyperLogLog is fine for rate limiting
2. Keep the last 24 hours of windows in the database
3. The Celery task just reads from Redis and writes to the DB

Sounds good? Let's see the code.
#+end_src

* Build the Root
- Very precise language
- Function names and definitions
- Which files are we working in
- We are building the foundational hard parts
- "Keep it simple, zen and to the point"
** Prompt
#+begin_src markdown
Let's build the core foundation. We'll work in these files:
- src/ratelimit/counter.py
- src/models/rate_window.py

Please create a function

def check_rate_limit(key: str, limit: int, window_seconds: int) -> bool

that uses Redis PFADD and PFCOUNT for approximate counting.

Uh, and we'll need datastructures as well. Please suggest better names, labels and help texts for these before coding the solution.

RateWindow:
   redis_key - str
   count - int (approximate)
   started_at - datetime
#+end_src

** Feel
- I'm in control
- Great input → Great output
- I'm not surprised by the output
- With these instructions, I could build this myself

* Build the Leaves
- Context is now great
- Fill in the blanks
- Let Claude do its thing
- Trust the LLM with implementation details
- Great for boilerplate, UI, CRUD, admin interfaces
- Read PR and give feedback

** Prompt
#+begin_src markdown
Now let's add the admin interface for RateWindow. It should have:
- All the standard fields visible
- Filters for started_at and redis_key patterns
- Search functionality
- Read-only fields since this is historical data

Also add a RateWindowChart that displays the last 24 hours with sorting and pagination. Make it look good and follow the patterns used elsewhere in the project.
#+end_src

** Feel
- I'm delegating the details
- Reaping the benefits of our structured approach
- I trust the output will be sensible
- This is what LLMs are great at
- The context is great so the rice grains falls in all the right places

* Commit
#+begin_src bash
clg() {
    unset ANTHROPIC_API_KEY
    claude -p -c "Your task is to commit and push ONLY the uncommitted changes in this git repository.

CRITICAL: You do NOT have access to previous commits in your history. Some changes may already
be committed. You must ONLY work with the uncommitted changes shown by 'git status' and 'git diff'.

WORKFLOW:
1. Run 'git status' to see what files are currently uncommitted (modified/added/deleted)
2. Run 'git diff' to review the actual uncommitted changes
3. Stage these uncommitted changes with 'git add'
4. Create a commit with a single-line descriptive message based ONLY on the uncommitted changes
5. Push the changes with 'git push'

DO NOT reference or include already-committed changes in your commit message.
DO NOT reference the current branch or issue number in the commit message

After successfully completing all steps, output a brief success message and exit immediately.
Do not wait for further instructions or ask any questions.

IMPORTANT TOOL RESTRICTIONS:
- You are ONLY allowed to use these tools:
  * Bash(git status:*) - to check repository status
  * Bash(git diff:*) - to view changes
  * Bash(git add:*) - to stage files
  * Bash(git commit:*) - to commit changes
  * Bash(git push:*) - to push changes
- You are NOT allowed to use any other tools including Read, Write, Edit, Grep, Glob, or any other Bash commands
- Stay focused on the git workflow only" \
    --allowedTools "Bash(git status:*)" "Bash(git diff:*)" "Bash(git add:*)" "Bash(git commit:*)" "Bash(git push:*)"
}
#+end_src

* Cleanup
- Remove LLM idioms and artifacts

** Prompt
#+begin_src markdown
Please clean up the code we just wrote:

- Move all imports to the top of the file
- Remove "before/after" style comments
- Remove placeholder comments like "TODO" or "FIXME" that we've already implemented
- Delete any commented-out old code
- Remove overly verbose comments that explain obvious things
- Consolidate any duplicate code
- Make sure formatting matches the rest of the project

Keep the code functionally identical, just make it look production-ready.
#+end_src

** Feel
- This makes it feel like my code
- Ready to commit
- No evidence of LLM artifacts

* Get feedback
- Compose email
- Update issue
- Ping stakeholders on slack

* Ship It
- Merge PR
- Update and close issue
