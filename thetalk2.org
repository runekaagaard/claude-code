#+title: Claude Code in Practice: Making It Work on Real Projects

* Template
*** Talk
*** Claude
#+begin_src markdown
#+end_src
*** Tooling

* Documentation
** CLAUDE.md
** llm/ folder with project-specific docs

* Building a Feature
** Exploration and Research
*** Talk
- Make Claude use a lot of tokens
- Great way to refresh own understanding
- Follow up for additional details
- Stepwise approach makes for good todo items

*** Claude
#+begin_src markdown
Hi Claude, let's start by researching how [TOPIC] works in the system.

First read:
- The current issue in [PROJECT MANAGEMENT TOOL]
- Any referenced emails
- Relevant documentation in the @llm folder

Then read these core files in full:
- @[FILE_1]
- @[FILE_2]

After that, reference relevant classes in [LONG_FILE] and do additional research as needed.

Finally, summarize your findings.
#+end_src

*** Tooling
#+begin_src bash
# Get absolute paths for files
$ realpath [file1] [file2]
#+end_src

#+begin_src elisp
(defun rk-realpath ()
  "Copy the full path of current buffer to kill ring"
  (interactive)
  (kill-new (buffer-file-name))
  (message "Copied: %s" (buffer-file-name)))

(defun rk-realpath-visible-buffers ()
  "Copy a newline separated list of full paths of visible buffers to kill ring."
  (interactive)
  (let ((paths '()))
    ;; Collect paths from all visible buffers
    (dolist (frame (frame-list))
      (dolist (window (window-list frame))
        (let* ((buffer (window-buffer window))
               (path (buffer-file-name buffer)))
          (when path
            (push path paths)))))

    ;; Create newline separated string and kill it
    (let ((paths-str (mapconcat #'identity (delete-dups (nreverse paths)) "\n")))
      (kill-new paths-str)
      (message "Copied %d visible buffer paths" (length (split-string paths-str "\n" t))))))
#+end_src

** Planning
*** Talk
- What are we building
- How will we build it
- Ask for questions and answer them
- Don't use plan mode
- "Don't code"

*** Claude
#+begin_src markdown
Today we are building [FEATURE]. I'm thinking we use this overall approach:

- [STEP_1]
- [STEP_2]
- [STEP_3]

Any questions? Feel free to do additional research before we start coding.
#+end_src

#+begin_src markdown
Great questions, I'm thinking the following:

1. [ANSWER_1]
2. [ANSWER_2]
3. [ANSWER_3]

Sounds good?
#+end_src

** Build the root
*** Talk
- Very precise language
- Function names and definitions
- Which files are we working in
- We are building the foundational hard parts
*** Claude
#+begin_src markdown
Let's build the core foundation. We'll work in these files:
- [FILE_1]
- [FILE_2]

Create a function `[function_name]([param1]: [Type1], [param2]: [Type2]) -> [ReturnType]` that:
1. [SPECIFIC_BEHAVIOR_1]
2. [SPECIFIC_BEHAVIOR_2]
3. [SPECIFIC_BEHAVIOR_3]

Then add a class `[ClassName]` with these methods:
- `[method1]()`: [PRECISE_DESCRIPTION]
- `[method2]()`: [PRECISE_DESCRIPTION]

Uh, and we'll need datastructures as well. Please suggest better names, labels and help texts for these before coding the solution.

SomeClass:
   [field1] - int
   [field2] - text, nullable

Use the pinspect tool to do adhoc checks of functionality as we go along.
#+end_src

*** Feel
- I'm in control
- I'm not suprised by the output
- We have great input, so ofcourse we get great output
- With the instructions given to the LLM I could build this

** Build the leaves
*** Talk
- High-level requirements
- Let Claude use its knowledge
- Trust the LLM with implementation details
- Great for boilerplate, UI, CRUD, admin interfaces
- We know what we want, not how to build it

*** Claude
#+begin_src markdown
Now let's add the admin interface for [MODEL_NAME]. It should have:
- All the standard fields visible
- Filters for [FIELD_1] and [FIELD_2]
- Search functionality
- The usual inline editing for related [RELATED_MODEL]

Also add a [UI_COMPONENT] that displays [DATA] with sorting and pagination. Make it look good and follow the patterns used elsewhere in the project.
#+end_src

*** Feel
- I'm delegating the details
- Claude knows the conventions better than I do
- I trust the output will be sensible
- This is what LLMs are great at
